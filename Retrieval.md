# Технический обзор статьи "Гибридный поиск для снижения галлюцинаций в больших языковых моделях: сравнительный анализ"

В данной статье Chandana sree Mala и соавторы представляют исследование эффективности различных методов поиска в контексте снижения галлюцинаций в больших языковых моделях (LLM). Работа фокусируется на сравнении трех основных подходов к поиску в системах Retrieval-Augmented Generation (RAG) и предлагает гибридный метод, который демонстрирует значительные улучшения по сравнению с традиционными подходами.

## Проблематика и мотивация исследования

Большие языковые модели, несмотря на их революционные возможности в обработке естественного языка, страдают от проблемы галлюцинаций – генерации фактически некорректной или необоснованной информации. Авторы указывают на RAG как на перспективный подход к решению этой проблемы путем обогащения ответов LLM внешними знаниями1. RAG системы решают несколько ключевых ограничений стандартных LLM, включая высокую стоимость обучения и дообучения, проблему галлюцинаций и ограничения, связанные с входным окном и отсечением знаний1.

## Методология исследования

Предлагаемая авторами система RAG состоит из двух основных модулей:

## Фаза поиска (Retrieval Phase)

В этой фазе авторы сравнивают три подхода к поиску релевантной информации:

1. **Разреженный поиск (Sparse Retrieval)** – основан на поиске по ключевым словам с использованием алгоритма BM25, который не учитывает семантические отношения между словами.
    
2. **Плотный поиск (Dense Retrieval)** – использует векторные представления (эмбеддинги) для улавливания семантического значения запросов и документов.
    
3. **Гибридный подход (RetHyb-RRF)** – предложенный авторами метод, который:
    
    - Включает модуль расширения запроса (Query Expansion) с использованием WordNet
        
    - Применяет динамическое взвешивание результатов разреженного и плотного поиска
        
    - Использует Reciprocal Rank Fusion (RRF) для объединения результатов
        
![[Pasted image 20250509143601.png]]
Особенностью предложенного гибридного метода является его адаптивность: система определяет характеристики запроса (специфичный или общий) и соответствующим образом корректирует веса для разреженного и плотного поиска. Для специфичных запросов больший вес получает разреженный поиск, для общих – плотный поиск.

## Фаза генерации (Generation Phase)

В этой фазе результаты поиска включаются в запрос к модели LLaMA-3-8B-Instruct, которая генерирует финальный ответ. Авторы используют стандартный промпт с подробными инструкциями в режиме zero-shot.
![[Pasted image 20250509143612.png]]
## Экспериментальная оценка

## Набор данных

Исследование проводилось на основе набора данных HaluBench – комплексного бенчмарка для оценки галлюцинаций, включающего 13,867 примеров. HaluBench объединяет 6 различных наборов данных: DROP, HaluEval, RAGTruth, FinanceBench, PubMedQA и COVIDQA.

## Метрики оценки

Авторы использовали две группы метрик:

1. **Метрики для оценки поиска**:
    
    - Mean Average Precision (MAP)
        
    - Normalized Discounted Cumulative Gain (NDCG)
        
2. **Метрики для оценки снижения галлюцинаций**:
    
    - Точность (Accuracy)
        
    - Уровень галлюцинаций (Hallucination Rate)
        
    - Уровень отказов (Rejection Rate)
        
    - Скорректированная точность (Adjusted Accuracy)
        

## Результаты исследования

## Эффективность поиска

Результаты показывают значительное превосходство гибридного подхода над разреженным и плотным поиском:

- MAP@3: RetHyb-RRF (0.897) > RetD (0.768) > RetS (0.724)
    
- NDCG@3: RetHyb-RRF (0.915) > RetD (0.783) > RetS (0.732)
    

## Снижение галлюцинаций

Гибридный подход также демонстрирует лучшие результаты по всем метрикам оценки галлюцинаций:

- Наивысшая точность: 92% на HaluEval и PubMedQA
    
- Наименьший уровень галлюцинаций: 4% на RAGTruth и PubMedQA
    
- Наименьший уровень отказов: 2% на HaluEval
    
- Скорректированная точность: наилучшие результаты на PubMedQA
    

Особенно значительное улучшение было отмечено на проблемных узкоспециализированных наборах данных CovidQA и FinanceBench, несмотря на то что именно здесь гибридный поиск показал относительно худшие (но всё равно лучшие среди сравниваемых подходов) результаты.

## Анализ результатов и выводы

Исследование убедительно демонстрирует важность качественного поиска для снижения галлюцинаций в LLM. Гибридный подход, объединяющий лексический и семантический поиск, обеспечивает более релевантный контекст для генерации ответов, что в свою очередь снижает вероятность галлюцинаций.

Ключевые преимущества гибридного подхода включают:

1. Расширение запроса для преодоления лексического разрыва между запросом и документами
    
2. Динамическое взвешивание для адаптации к характеристикам конкретного запроса
    
3. Эффективное использование RRF для объединения результатов разных методов поиска
    

Авторы отмечают, что предложенный метод особенно эффективен для снижения галлюцинаций в медицинской и финансовой областях, которые традиционно считаются более сложными.

## Направления дальнейших исследований

Авторы предлагают следующие перспективы для будущей работы:

1. Оптимизация методов с использованием продвинутых алгоритмов переранжирования для дальнейшего уточнения выбора документов
    
2. Адаптация предложенного метода к узкоспециализированным наборам данных
    
3. Исследование влияния предложенного метода на другие типы LLM для оценки его более широкой применимости и эффективности
    

## Заключение

Данное исследование вносит значимый вклад в область снижения галлюцинаций в больших языковых моделях, предлагая эффективный гибридный подход к поиску релевантной информации. Результаты экспериментов убедительно показывают, что предложенный гибридный метод превосходит традиционные подходы к поиску по всем рассмотренным метрикам, обеспечивая более качественный контекст для генерации ответов и значительно снижая уровень галлюцинаций.

Исследование подчеркивает важность интеграции различных методов поиска для достижения лучшей устойчивости и надежности в системах RAG, что особенно актуально в контексте растущего использования LLM для решения ответственных задач в различных предметных областях.