# Анализ гибридной системы информационного поиска и генерации ответов для регулятивных текстов

В статье "A Hybrid Approach to Information Retrieval and Answer Generation for Regulatory Texts", опубликованной 24 февраля 2025 года, представлен инновационный подход к обработке сложных регулятивных документов. Авторы Jhon Rayo, Raúl de la Rosa и Mario Garrido из Universidad de los Andes (Колумбия) разработали систему, сочетающую лексический и семантический поиск с генерацией ответов для более эффективной работы с нормативно-правовыми документами. Исследование демонстрирует, что гибридный подход значительно превосходит отдельное использование как лексических, так и семантических методов, позволяя достичь большей точности и полноты при извлечении релевантной информации из сложных регулятивных текстов.

## Проблематика и актуальность исследования

Регулятивные документы представляют серьезный вызов для систем информационного поиска по нескольким причинам. Во-первых, они содержат специализированную терминологию и нюансированный язык, что затрудняет точное сопоставление запросов с релевантными документами[12](https://arxiv.org/pdf/2502.16767.pdf). Во-вторых, традиционные методы поиска, основанные на статистической частоте терминов (например, tf-idf), не способны улавливать семантические связи, характерные для регулятивной лексики[12](https://arxiv.org/pdf/2502.16767.pdf). В-третьих, синонимы, перефразирования и отраслевой жаргон часто затрудняют связь между запросами и соответствующими документами[12](https://arxiv.org/pdf/2502.16767.pdf).

Авторы справедливо отмечают, что хотя алгоритм BM25 (Best Match 25) является эффективным для лексического поиска, он не справляется с семантическими соответствиями, особенно в регулятивных областях, где терминология может сильно варьироваться для обозначения одних и тех же понятий[12](https://arxiv.org/pdf/2502.16767.pdf). Это создает потребность в более совершенных методах, способных понимать контекст и значение запросов, а не только их лексическую форму.

## Методология исследования

## Использованный датасет

Исследование проводилось на датасете ObliQA, содержащем 27 869 регулятивных вопросов из 40 документов, предоставленных Abu Dhabi Global Markets (ADGM) - международным финансовым центром и свободной экономической зоной, расположенной в Абу-Даби, столице Объединенных Арабских Эмиратов[11](https://en.wikipedia.org/wiki/Abu_Dhabi_Global_Market)[12](https://arxiv.org/pdf/2502.16767.pdf). Датасет был разделен на три части: тренировочную (22 295 вопросов), тестовую (2 786 вопросов) и валидационную (2 788 вопросов)[12](https://arxiv.org/pdf/2502.16767.pdf).

Каждый вопрос в датасете сопровождался одним или несколькими текстовыми фрагментами, содержащими информацию, необходимую для ответа на него. Данные хранились в формате JSON и включали идентификатор вопроса, сам вопрос, связанные с ним фрагменты и метаданные[12](https://arxiv.org/pdf/2502.16767.pdf).

## Файн-тюнинг модели

Ключевым компонентом предложенной системы является файн-тюнинг предварительно обученной модели BAAI/bge-small-en-v1.5, основанной на архитектуре BERT[12](https://arxiv.org/pdf/2502.16767.pdf). Процесс дообучения включал следующие шаги:

1. Применение функции потерь, направленной на максимизацию сходства между вопросами и связанными с ними текстовыми фрагментами.
    
2. Увеличение размерности векторных представлений с 384 до 512 для более точного улавливания семантических нюансов в регулятивных текстах.
    
3. Обучение модели на GPU NVIDIA A40 с использованием библиотеки SentenceTransformer в течение 10 эпох с размером батча 64 и скоростью обучения 2×10^-4[12](https://arxiv.org/pdf/2502.16767.pdf).
    

Особенно важным аспектом обучения было использование функции потерь MultipleNegativesRankingLoss, которая рассматривает все непарные примеры в батче как отрицательные, что особенно хорошо подходит для сценариев с только положительными парами[7](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/MultipleNegativesRankingLoss.py)[10](https://arxiv.org/pdf/2502.16767.pdf)[12](https://arxiv.org/pdf/2502.16767.pdf). Эта функция потерь оптимизирует модель, чтобы для заданного якоря (например, вопроса) сходство с соответствующим положительным примером (ответом) было выше, чем сходство с любым другим положительным или отрицательным примером в батче[7](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/MultipleNegativesRankingLoss.py)[10](https://arxiv.org/pdf/2502.16767.pdf).

## Система информационного поиска

Авторы разработали комплексный конвейер обработки данных, включающий следующие этапы:

1. Расширение сокращений (например, преобразование "don't" в "do not") для обеспечения согласованности.
    
2. Нормализация (преобразование текста в нижний регистр и удаление неалфавитно-цифровых символов).
    
3. Удаление избыточных пробелов для обеспечения единообразия.
    
4. Сохранение специальных символов, критически важных для юридических документов.
    
5. Удаление стоп-слов с использованием наборов из библиотек nltk и scikit-learn.
    
6. Стемминг с применением алгоритма Snowball Stemmer для приведения слов к их корневым формам.
    
7. Токенизация с генерацией униграмм и биграмм для улавливания как отдельных терминов, так и комбинаций слов[12](https://arxiv.org/pdf/2502.16767.pdf).
    

На основе этого конвейера были реализованы три подхода к поиску:

1. **BM25 (базовый)**: настроенный с параметрами k=1,5 и b=0,75[12](https://arxiv.org/pdf/2502.16767.pdf)[18](https://vc.ru/marketing/1812189-algoritm-bm25-i-ego-modifikaciya-bm25f-kak-poiskovye-sistemy-ocenivayut-relevantnost-kontenta).
    
2. **Семантический поиск**: использующий только файн-тюнинг модели для семантических соответствий[12](https://arxiv.org/pdf/2502.16767.pdf).
    
3. **Гибридная система**: комбинирующая BM25 и файн-тюнинг модели, с агрегированной оценкой, вычисляемой по формуле:  
    Score = α · Semantic Score + (1−α) · Lexical Score,  
    где α=0,65 для придания несколько большего веса семантическому соответствию при сохранении значимого вклада от лексического поиска[12](https://arxiv.org/pdf/2502.16767.pdf).
    

Такая нормализация обеспечивает, что ни один из подходов не доминирует в итоговом ранжировании исключительно из-за различий в распределении оценок.

## Генерация ответов на основе извлеченной информации

## Подход RAG (Retrieval Augmented Generation)

Для генерации ответов на регулятивные вопросы авторы применили технологию RAG (генерация с дополненной выборкой), которая объединяет возможности поиска и генерации текста[6](https://habr.com/ru/articles/841428/)[14](https://aws.amazon.com/ru/what-is/retrieval-augmented-generation/)[17](https://sysblok.ru/glossary/chto-takoe-rag/)[19](https://gitverse.ru/blog/articles/ai/216-chto-takoe-rag-retrieval-augmented-generation-prostymi-slovami-i-osnovnye-principy). RAG позволяет большим языковым моделям (LLM) генерировать ответы на основе информации, которой не было в их обучающих данных, что особенно ценно для работы с регулятивными документами, требующими высокой точности и актуальности[17](https://sysblok.ru/glossary/chto-takoe-rag/)[19](https://gitverse.ru/blog/articles/ai/216-chto-takoe-rag-retrieval-augmented-generation-prostymi-slovami-i-osnovnye-principy)[21](https://ya.zerocoder.ru/pgt-chto-takoe-retrieval-augmented-generation-rag-v-prompt-engineering/).

Процесс генерации ответов в системе включал следующие шаги:

1. Извлечение до 10 релевантных фрагментов из корпуса в ответ на регулятивный вопрос.
    
2. Отбор только тех фрагментов, которые имеют оценку релевантности не менее 0,72.
    
3. Прекращение обработки фрагментов, когда оценка релевантности падает более чем на 0,1 по сравнению с предыдущим фрагментом, что позволяет поддерживать релевантность и связность входных данных.
    
4. Передача отобранных фрагментов в языковую модель для синтеза краткого и связного ответа[12](https://arxiv.org/pdf/2502.16767.pdf).
    

## Оценка качества ответов

Для оценки качества генерируемых ответов авторы использовали метрику RePASs (Regulatory Passage Answer Stability Score), которая оценивает стабильность и точность ответов по трем ключевым измерениям:

1. **Оценка следования (Es)**: измеряет, насколько каждое предложение в сгенерированном ответе подтверждается предложениями из извлеченных фрагментов.
    
2. **Оценка противоречия (Cs)**: оценивает, противоречит ли какое-либо предложение в сгенерированном ответе информации из извлеченных фрагментов.
    
3. **Оценка покрытия обязательств (OCs)**: проверяет, охватывает ли сгенерированный ответ все обязательства, присутствующие в извлеченных фрагментах[12](https://arxiv.org/pdf/2502.16767.pdf).
    

Авторы сравнили производительность нескольких языковых моделей:

- GPT 3.5 Turbo
    
- GPT-4o Mini
    
- Llama 3.1
    

GPT 3.5 Turbo продемонстрировала наивысший показатель RePASs (0,57), значительно превзойдя как GPT-4o Mini (0,44), так и Llama 3.1 (0,37), что привело к ее выбору в качестве основной модели для системы[12](https://arxiv.org/pdf/2502.16767.pdf).

## Результаты экспериментов

Эксперименты убедительно показали превосходство гибридного подхода над отдельными методами поиска. В частности, гибридная система достигла следующих показателей:

- Recall@10: 0,8333 (против 0,7611 у базового BM25 и 0,8103 у семантического поиска)
    
- MAP@10: 0,7016 (против 0,6237 у базового BM25 и 0,6286 у семантического поиска)
    
- Recall@20: 0,8704 (против 0,8022 у базового BM25 и 0,8622 у семантического поиска)
    
- MAP@20: 0,7053 (против 0,6274 у базового BM25 и 0,6334 у семантического поиска)[12](https://arxiv.org/pdf/2502.16767.pdf)
    

Эти результаты наглядно демонстрируют, что объединение лексического и семантического поиска позволяет достичь значительно лучших результатов, чем использование каждого метода по отдельности.

В отношении качества генерируемых ответов, хотя система достигла умеренных улучшений в покрытии обязательств (OCs) и несколько лучшей обработки противоречий (Cs), оценка следования (Es) выявила области для дальнейшей оптимизации. Это указывает на то, что, хотя гибридная система поиска улучшает релевантность ответов, процесс синтеза с использованием GPT 3.5 Turbo показывает сниженную производительность в улавливании степени, в которой генерируемые ответы поддерживаются извлеченными фрагментами[12](https://arxiv.org/pdf/2502.16767.pdf).

## Сравнение с другими подходами

Гибридный подход, предложенный авторами, имеет существенные преимущества по сравнению с традиционными методами поиска и генерации:

1. **По сравнению с BM25**: Традиционный алгоритм BM25, хотя и является эффективным для лексического поиска, не способен улавливать семантические отношения между запросами и документами[2](https://habr.com/ru/articles/860830/)[3](https://ru.megaindex.com/support/faq/bm25)[18](https://vc.ru/marketing/1812189-algoritm-bm25-i-ego-modifikaciya-bm25f-kak-poiskovye-sistemy-ocenivayut-relevantnost-kontenta)[20](https://ru.wikipedia.org/wiki/Okapi_BM25). Гибридный подход решает эту проблему, дополняя лексический поиск семантическим сопоставлением.
    
2. **По сравнению с чисто семантическим поиском**: Плотные (dense) векторные представления эффективны для семантического поиска, но могут упускать точные лексические совпадения[4](https://zilliz.com/learn/sparse-and-dense-embeddings)[16](https://milvus.io/ru/blog/semantic-search-vs-full-text-search-which-one-should-i-choose-with-milvus-2-5.md). Гибридный подход сочетает преимущества обоих методов, обеспечивая как точность лексического совпадения, так и понимание семантики.
    
3. **По сравнению с традиционными RAG-системами**: Стандартные системы RAG часто используют только один тип поиска[6](https://habr.com/ru/articles/841428/)[14](https://aws.amazon.com/ru/what-is/retrieval-augmented-generation/)[19](https://gitverse.ru/blog/articles/ai/216-chto-takoe-rag-retrieval-augmented-generation-prostymi-slovami-i-osnovnye-principy). Предложенная гибридная система, сочетающая лексический и семантический поиск, обеспечивает более полное и точное извлечение релевантной информации.
    

## Практическое значение и возможные применения

Предложенная гибридная система имеет широкий спектр потенциальных применений в различных областях, связанных с обработкой регулятивных документов:

1. **Соблюдение нормативных требований**: Система может помочь компаниям отслеживать и соблюдать различные регулятивные требования, быстро извлекая релевантную информацию из больших корпусов нормативных документов[9](https://github.com/RegNLP/RePASs)[12](https://arxiv.org/pdf/2502.16767.pdf).
    
2. **Юридические исследования**: Юристы и правовые исследователи могут использовать систему для поиска прецедентов и релевантных законодательных актов, что существенно ускорит процесс юридических исследований[12](https://arxiv.org/pdf/2502.16767.pdf).
    
3. **Финансовое регулирование**: В финансовом секторе, где регулирование особенно строго, система может помочь финансовым учреждениям оставаться в курсе изменений в нормативных требованиях[11](https://en.wikipedia.org/wiki/Abu_Dhabi_Global_Market)[12](https://arxiv.org/pdf/2502.16767.pdf).
    
4. **Медицинское регулирование**: В медицинской сфере, где несоблюдение регулятивных требований может иметь серьезные последствия, система может обеспечить быстрый доступ к актуальной нормативной информации[12](https://arxiv.org/pdf/2502.16767.pdf).
    

## Ограничения и направления для будущих исследований

Несмотря на многообещающие результаты, исследование имеет ряд ограничений, которые открывают возможности для будущих работ:

1. **Улучшение оценки следования (Es)**: Текущая система показывает относительно низкую оценку следования, что указывает на необходимость улучшения соответствия между генерируемыми ответами и извлеченными фрагментами[12](https://arxiv.org/pdf/2502.16767.pdf).
    
2. **Дообучение языковых моделей на доменно-специфичных корпусах**: Файн-тюнинг языковых моделей на регулятивных текстах может улучшить их соответствие регулятивному контексту и повысить качество генерируемых ответов[12](https://arxiv.org/pdf/2502.16767.pdf).
    
3. **Оптимизация пороговых значений поиска**: Дальнейшая настройка параметров поиска может улучшить семантический охват и повысить релевантность извлекаемой информации[12](https://arxiv.org/pdf/2502.16767.pdf).
    
4. **Разработка продвинутых механизмов оценки**: Создание более совершенных механизмов оценки для баланса между точностью и полнотой может повысить общую эффективность системы[12](https://arxiv.org/pdf/2502.16767.pdf).
    

## Заключение

Исследование, представленное в статье "A Hybrid Approach to Information Retrieval and Answer Generation for Regulatory Texts", демонстрирует эффективность гибридного подхода, интегрирующего лексические и семантические методы поиска, для решения сложных задач извлечения и синтеза информации из регулятивных текстов. Предложенная система последовательно превосходит автономные лексические или семантические подходы, достигая значительных улучшений в таких метриках, как Recall@10 и MAP@10.

Исследование также подтверждает потенциал больших языковых моделей для синтеза кратких и всеобъемлющих ответов на основе структурированной информации, извлеченной гибридной системой поиска. Эта работа представляет собой важный шаг вперед в развитии инструментов обработки естественного языка для приложений, ориентированных на соблюдение нормативных требований, и закладывает основу для более эффективных систем вопросов и ответов в специализированных областях.# Анализ гибридной системы информационного поиска и генерации ответов для регулятивных текстов

В статье "A Hybrid Approach to Information Retrieval and Answer Generation for Regulatory Texts", опубликованной 24 февраля 2025 года, представлен инновационный подход к обработке сложных регулятивных документов. Авторы Jhon Rayo, Raúl de la Rosa и Mario Garrido из Universidad de los Andes (Колумбия) разработали систему, сочетающую лексический и семантический поиск с генерацией ответов для более эффективной работы с нормативно-правовыми документами. Исследование демонстрирует, что гибридный подход значительно превосходит отдельное использование как лексических, так и семантических методов, позволяя достичь большей точности и полноты при извлечении релевантной информации из сложных регулятивных текстов.

## Проблематика и актуальность исследования

Регулятивные документы представляют серьезный вызов для систем информационного поиска по нескольким причинам. Во-первых, они содержат специализированную терминологию и нюансированный язык, что затрудняет точное сопоставление запросов с релевантными документами[12](https://arxiv.org/pdf/2502.16767.pdf). Во-вторых, традиционные методы поиска, основанные на статистической частоте терминов (например, tf-idf), не способны улавливать семантические связи, характерные для регулятивной лексики[12](https://arxiv.org/pdf/2502.16767.pdf). В-третьих, синонимы, перефразирования и отраслевой жаргон часто затрудняют связь между запросами и соответствующими документами[12](https://arxiv.org/pdf/2502.16767.pdf).

Авторы справедливо отмечают, что хотя алгоритм BM25 (Best Match 25) является эффективным для лексического поиска, он не справляется с семантическими соответствиями, особенно в регулятивных областях, где терминология может сильно варьироваться для обозначения одних и тех же понятий[12](https://arxiv.org/pdf/2502.16767.pdf). Это создает потребность в более совершенных методах, способных понимать контекст и значение запросов, а не только их лексическую форму.

## Методология исследования

## Использованный датасет

Исследование проводилось на датасете ObliQA, содержащем 27 869 регулятивных вопросов из 40 документов, предоставленных Abu Dhabi Global Markets (ADGM) - международным финансовым центром и свободной экономической зоной, расположенной в Абу-Даби, столице Объединенных Арабских Эмиратов[11](https://en.wikipedia.org/wiki/Abu_Dhabi_Global_Market)[12](https://arxiv.org/pdf/2502.16767.pdf). Датасет был разделен на три части: тренировочную (22 295 вопросов), тестовую (2 786 вопросов) и валидационную (2 788 вопросов)[12](https://arxiv.org/pdf/2502.16767.pdf).

Каждый вопрос в датасете сопровождался одним или несколькими текстовыми фрагментами, содержащими информацию, необходимую для ответа на него. Данные хранились в формате JSON и включали идентификатор вопроса, сам вопрос, связанные с ним фрагменты и метаданные[12](https://arxiv.org/pdf/2502.16767.pdf).

## Файн-тюнинг модели

Ключевым компонентом предложенной системы является файн-тюнинг предварительно обученной модели BAAI/bge-small-en-v1.5, основанной на архитектуре BERT[12](https://arxiv.org/pdf/2502.16767.pdf). Процесс дообучения включал следующие шаги:

1. Применение функции потерь, направленной на максимизацию сходства между вопросами и связанными с ними текстовыми фрагментами.
    
2. Увеличение размерности векторных представлений с 384 до 512 для более точного улавливания семантических нюансов в регулятивных текстах.
    
3. Обучение модели на GPU NVIDIA A40 с использованием библиотеки SentenceTransformer в течение 10 эпох с размером батча 64 и скоростью обучения 2×10^-4[12](https://arxiv.org/pdf/2502.16767.pdf).
    

Особенно важным аспектом обучения было использование функции потерь MultipleNegativesRankingLoss, которая рассматривает все непарные примеры в батче как отрицательные, что особенно хорошо подходит для сценариев с только положительными парами[7](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/MultipleNegativesRankingLoss.py)[10](https://arxiv.org/pdf/2502.16767.pdf)[12](https://arxiv.org/pdf/2502.16767.pdf). Эта функция потерь оптимизирует модель, чтобы для заданного якоря (например, вопроса) сходство с соответствующим положительным примером (ответом) было выше, чем сходство с любым другим положительным или отрицательным примером в батче[7](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/MultipleNegativesRankingLoss.py)[10](https://arxiv.org/pdf/2502.16767.pdf).

## Система информационного поиска

Авторы разработали комплексный конвейер обработки данных, включающий следующие этапы:

1. Расширение сокращений (например, преобразование "don't" в "do not") для обеспечения согласованности.
    
2. Нормализация (преобразование текста в нижний регистр и удаление неалфавитно-цифровых символов).
    
3. Удаление избыточных пробелов для обеспечения единообразия.
    
4. Сохранение специальных символов, критически важных для юридических документов.
    
5. Удаление стоп-слов с использованием наборов из библиотек nltk и scikit-learn.
    
6. Стемминг с применением алгоритма Snowball Stemmer для приведения слов к их корневым формам.
    
7. Токенизация с генерацией униграмм и биграмм для улавливания как отдельных терминов, так и комбинаций слов[12](https://arxiv.org/pdf/2502.16767.pdf).
    

На основе этого конвейера были реализованы три подхода к поиску:

1. **BM25 (базовый)**: настроенный с параметрами k=1,5 и b=0,75[12](https://arxiv.org/pdf/2502.16767.pdf)[18](https://vc.ru/marketing/1812189-algoritm-bm25-i-ego-modifikaciya-bm25f-kak-poiskovye-sistemy-ocenivayut-relevantnost-kontenta).
    
2. **Семантический поиск**: использующий только файн-тюнинг модели для семантических соответствий[12](https://arxiv.org/pdf/2502.16767.pdf).
    
3. **Гибридная система**: комбинирующая BM25 и файн-тюнинг модели, с агрегированной оценкой, вычисляемой по формуле:  
    Score = α · Semantic Score + (1−α) · Lexical Score,  
    где α=0,65 для придания несколько большего веса семантическому соответствию при сохранении значимого вклада от лексического поиска[12](https://arxiv.org/pdf/2502.16767.pdf).
    

Такая нормализация обеспечивает, что ни один из подходов не доминирует в итоговом ранжировании исключительно из-за различий в распределении оценок.

## Генерация ответов на основе извлеченной информации

## Подход RAG (Retrieval Augmented Generation)

Для генерации ответов на регулятивные вопросы авторы применили технологию RAG (генерация с дополненной выборкой), которая объединяет возможности поиска и генерации текста[6](https://habr.com/ru/articles/841428/)[14](https://aws.amazon.com/ru/what-is/retrieval-augmented-generation/)[17](https://sysblok.ru/glossary/chto-takoe-rag/)[19](https://gitverse.ru/blog/articles/ai/216-chto-takoe-rag-retrieval-augmented-generation-prostymi-slovami-i-osnovnye-principy). RAG позволяет большим языковым моделям (LLM) генерировать ответы на основе информации, которой не было в их обучающих данных, что особенно ценно для работы с регулятивными документами, требующими высокой точности и актуальности[17](https://sysblok.ru/glossary/chto-takoe-rag/)[19](https://gitverse.ru/blog/articles/ai/216-chto-takoe-rag-retrieval-augmented-generation-prostymi-slovami-i-osnovnye-principy)[21](https://ya.zerocoder.ru/pgt-chto-takoe-retrieval-augmented-generation-rag-v-prompt-engineering/).

Процесс генерации ответов в системе включал следующие шаги:

1. Извлечение до 10 релевантных фрагментов из корпуса в ответ на регулятивный вопрос.
    
2. Отбор только тех фрагментов, которые имеют оценку релевантности не менее 0,72.
    
3. Прекращение обработки фрагментов, когда оценка релевантности падает более чем на 0,1 по сравнению с предыдущим фрагментом, что позволяет поддерживать релевантность и связность входных данных.
    
4. Передача отобранных фрагментов в языковую модель для синтеза краткого и связного ответа[12](https://arxiv.org/pdf/2502.16767.pdf).
    

## Оценка качества ответов

Для оценки качества генерируемых ответов авторы использовали метрику RePASs (Regulatory Passage Answer Stability Score), которая оценивает стабильность и точность ответов по трем ключевым измерениям:

1. **Оценка следования (Es)**: измеряет, насколько каждое предложение в сгенерированном ответе подтверждается предложениями из извлеченных фрагментов.
    
2. **Оценка противоречия (Cs)**: оценивает, противоречит ли какое-либо предложение в сгенерированном ответе информации из извлеченных фрагментов.
    
3. **Оценка покрытия обязательств (OCs)**: проверяет, охватывает ли сгенерированный ответ все обязательства, присутствующие в извлеченных фрагментах[12](https://arxiv.org/pdf/2502.16767.pdf).
    

Авторы сравнили производительность нескольких языковых моделей:

- GPT 3.5 Turbo
    
- GPT-4o Mini
    
- Llama 3.1
    

GPT 3.5 Turbo продемонстрировала наивысший показатель RePASs (0,57), значительно превзойдя как GPT-4o Mini (0,44), так и Llama 3.1 (0,37), что привело к ее выбору в качестве основной модели для системы[12](https://arxiv.org/pdf/2502.16767.pdf).

## Результаты экспериментов

Эксперименты убедительно показали превосходство гибридного подхода над отдельными методами поиска. В частности, гибридная система достигла следующих показателей:

- Recall@10: 0,8333 (против 0,7611 у базового BM25 и 0,8103 у семантического поиска)
    
- MAP@10: 0,7016 (против 0,6237 у базового BM25 и 0,6286 у семантического поиска)
    
- Recall@20: 0,8704 (против 0,8022 у базового BM25 и 0,8622 у семантического поиска)
    
- MAP@20: 0,7053 (против 0,6274 у базового BM25 и 0,6334 у семантического поиска)[12](https://arxiv.org/pdf/2502.16767.pdf)
    

Эти результаты наглядно демонстрируют, что объединение лексического и семантического поиска позволяет достичь значительно лучших результатов, чем использование каждого метода по отдельности.

В отношении качества генерируемых ответов, хотя система достигла умеренных улучшений в покрытии обязательств (OCs) и несколько лучшей обработки противоречий (Cs), оценка следования (Es) выявила области для дальнейшей оптимизации. Это указывает на то, что, хотя гибридная система поиска улучшает релевантность ответов, процесс синтеза с использованием GPT 3.5 Turbo показывает сниженную производительность в улавливании степени, в которой генерируемые ответы поддерживаются извлеченными фрагментами[12](https://arxiv.org/pdf/2502.16767.pdf).

## Сравнение с другими подходами

Гибридный подход, предложенный авторами, имеет существенные преимущества по сравнению с традиционными методами поиска и генерации:

1. **По сравнению с BM25**: Традиционный алгоритм BM25, хотя и является эффективным для лексического поиска, не способен улавливать семантические отношения между запросами и документами[2](https://habr.com/ru/articles/860830/)[3](https://ru.megaindex.com/support/faq/bm25)[18](https://vc.ru/marketing/1812189-algoritm-bm25-i-ego-modifikaciya-bm25f-kak-poiskovye-sistemy-ocenivayut-relevantnost-kontenta)[20](https://ru.wikipedia.org/wiki/Okapi_BM25). Гибридный подход решает эту проблему, дополняя лексический поиск семантическим сопоставлением.
    
2. **По сравнению с чисто семантическим поиском**: Плотные (dense) векторные представления эффективны для семантического поиска, но могут упускать точные лексические совпадения[4](https://zilliz.com/learn/sparse-and-dense-embeddings)[16](https://milvus.io/ru/blog/semantic-search-vs-full-text-search-which-one-should-i-choose-with-milvus-2-5.md). Гибридный подход сочетает преимущества обоих методов, обеспечивая как точность лексического совпадения, так и понимание семантики.
    
3. **По сравнению с традиционными RAG-системами**: Стандартные системы RAG часто используют только один тип поиска[6](https://habr.com/ru/articles/841428/)[14](https://aws.amazon.com/ru/what-is/retrieval-augmented-generation/)[19](https://gitverse.ru/blog/articles/ai/216-chto-takoe-rag-retrieval-augmented-generation-prostymi-slovami-i-osnovnye-principy). Предложенная гибридная система, сочетающая лексический и семантический поиск, обеспечивает более полное и точное извлечение релевантной информации.
    

## Практическое значение и возможные применения

Предложенная гибридная система имеет широкий спектр потенциальных применений в различных областях, связанных с обработкой регулятивных документов:

1. **Соблюдение нормативных требований**: Система может помочь компаниям отслеживать и соблюдать различные регулятивные требования, быстро извлекая релевантную информацию из больших корпусов нормативных документов[9](https://github.com/RegNLP/RePASs)[12](https://arxiv.org/pdf/2502.16767.pdf).
    
2. **Юридические исследования**: Юристы и правовые исследователи могут использовать систему для поиска прецедентов и релевантных законодательных актов, что существенно ускорит процесс юридических исследований[12](https://arxiv.org/pdf/2502.16767.pdf).
    
3. **Финансовое регулирование**: В финансовом секторе, где регулирование особенно строго, система может помочь финансовым учреждениям оставаться в курсе изменений в нормативных требованиях[11](https://en.wikipedia.org/wiki/Abu_Dhabi_Global_Market)[12](https://arxiv.org/pdf/2502.16767.pdf).
    
4. **Медицинское регулирование**: В медицинской сфере, где несоблюдение регулятивных требований может иметь серьезные последствия, система может обеспечить быстрый доступ к актуальной нормативной информации[12](https://arxiv.org/pdf/2502.16767.pdf).
    

## Ограничения и направления для будущих исследований

Несмотря на многообещающие результаты, исследование имеет ряд ограничений, которые открывают возможности для будущих работ:

1. **Улучшение оценки следования (Es)**: Текущая система показывает относительно низкую оценку следования, что указывает на необходимость улучшения соответствия между генерируемыми ответами и извлеченными фрагментами[12](https://arxiv.org/pdf/2502.16767.pdf).
    
2. **Дообучение языковых моделей на доменно-специфичных корпусах**: Файн-тюнинг языковых моделей на регулятивных текстах может улучшить их соответствие регулятивному контексту и повысить качество генерируемых ответов[12](https://arxiv.org/pdf/2502.16767.pdf).
    
3. **Оптимизация пороговых значений поиска**: Дальнейшая настройка параметров поиска может улучшить семантический охват и повысить релевантность извлекаемой информации[12](https://arxiv.org/pdf/2502.16767.pdf).
    
4. **Разработка продвинутых механизмов оценки**: Создание более совершенных механизмов оценки для баланса между точностью и полнотой может повысить общую эффективность системы[12](https://arxiv.org/pdf/2502.16767.pdf).
    

## Заключение

Исследование, представленное в статье "A Hybrid Approach to Information Retrieval and Answer Generation for Regulatory Texts", демонстрирует эффективность гибридного подхода, интегрирующего лексические и семантические методы поиска, для решения сложных задач извлечения и синтеза информации из регулятивных текстов. Предложенная система последовательно превосходит автономные лексические или семантические подходы, достигая значительных улучшений в таких метриках, как Recall@10 и MAP@10.

Исследование также подтверждает потенциал больших языковых моделей для синтеза кратких и всеобъемлющих ответов на основе структурированной информации, извлеченной гибридной системой поиска. Эта работа представляет собой важный шаг вперед в развитии инструментов обработки естественного языка для приложений, ориентированных на соблюдение нормативных требований, и закладывает основу для более эффективных систем вопросов и ответов в специализированных областях.
