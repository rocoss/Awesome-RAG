
# Тезисный разбор статьи ["Can Knowledge Graphs Reduce Hallucinations in LLMs?: A Survey"](https://arxiv.org/html/2311.07914v2)

Данная статья представляет собой систематический обзор методов использования графов знаний для уменьшения галлюцинаций в больших языковых моделях (LLMs). Галлюцинации - это главная проблема современных LLMs, когда они генерируют неточную или полностью ложную информацию, звучащую правдоподобно. Рассмотрим детально каждый раздел статьи.

## 1. Введение

В данном разделе авторы представляют проблему галлюцинаций в больших языковых моделях (LLMs) и обосновывают актуальность исследования. LLMs обучаются на обширных наборах данных и действуют по принципу предсказания следующего токена в последовательности, что создает вероятностный характер их работы[1]. 

![Идея](https://arxiv.org/html/2311.07914v2/extracted/5474405/Figures/Intro.png)

Основные причины возникновения галлюцинаций в LLMs:
- Стохастический характер процесса декодирования
- Наличие дезинформации, предвзятостей и неточностей в обучающих данных
- Трудности в интерпретации фраз при неясном контексте или отсутствии знаний в модели

Авторы отмечают, что добавление контекстуально релевантных и точных внешних знаний может значительно помочь модели в восстановлении важной информации[1]. Одним из перспективных направлений является интеграция графов знаний (KGs) в LLMs для улучшения их производительности и обеспечения более надежного процесса рассуждения.

Обзор классифицирует методы улучшения LLMs с помощью графов знаний на три основные категории:
1. Knowledge-Aware Inference (выводы с учетом знаний)
2. Knowledge-Aware Learning (обучение с учетом знаний)
3. Knowledge-Aware Validation (проверка с учетом знаний)
![Таксономия](https://github.com/rocoss/Awesome-RAG/blob/main/images/ontology/1.png)
## 2. Предварительные сведения

### 2.1. Большие языковые модели

В этом подразделе рассматриваются основы языкового моделирования - ключевой задачи в области обработки естественного языка. Нейронные вероятностные языковые модели (Bengio et al., 2000) нацелены на оценку вероятности текстовой последовательности путем вычисления вероятности каждого токена с учетом предшествующих токенов.

Формула для вычисления вероятности последовательности:
$$ p(x) = \prod_{i=1}^{N} p(x_i | x_1, x_2...x_{i-1}) $$

Архитектура трансформеров (Vaswani et al., 2017) значительно продвинула нейронные вероятностные языковые модели, обеспечив эффективную параллельную обработку и распознавание долгосрочных зависимостей в тексте. В сочетании с передовыми методами обучения, такими как инструктивная настройка и обучение с подкреплением от человеческой обратной связи (RLHF), были созданы передовые LLMs, такие как GPT-3, GPT-4 и PaLM.

### 2.2. Графы знаний

Графы знаний (KGs) организуют информацию в структурированном формате, отображая отношения между реальными сущностями, делая их понятными как для людей, так и для машин. Они хранят данные в виде триплетов в графе, где узлы представляют сущности (например, людей или места), а рёбра - отношения между ними.

Области применения графов знаний:
- Семантический поиск
- Управление корпоративными знаниями
- Оптимизация цепочек поставок
- Образование
- Обнаружение финансового мошенничества
- Кибербезопасность
- Рекомендательные системы
- Системы вопросов и ответов

## 3. LLMs с расширенными графами знаний
![Вывод на основе знаний путем включения поиска, дополненного KG ](https://arxiv.org/html/2311.07914v2/extracted/5474405/Figures/Method_1.png)
Авторы указывают на три основные точки отказа LLMs: непонимание вопроса из-за отсутствия контекста, недостаточность знаний для точного ответа и неспособность вспомнить конкретные факты. В этом разделе рассматриваются методологии, направленные на смягчение галлюцинаций и улучшение способностей рассуждения LLMs путем расширения с помощью графов знаний.

### 3.1. Выводы с учетом знаний

В LLMs "вывод" означает генерацию текста или предсказаний на основе предварительно обученной модели и входного контекста. Проблемы включают неверные или неоптимальные выходные данные из-за неоднозначных входных данных, неясного контекста, пробелов в знаниях, предвзятостей в обучающих данных или неспособности обобщать на непредставленные сценарии.

#### 3.1.1. Расширенный графами знаний поиск

Модели генерации с расширенным поиском, такие как RAG (Lewis et al., 2020) и RALM (Ram et al., 2023), повышают контекстуальную осведомленность LLMs для задач, требующих знаний, предоставляя релевантные документы во время генерации, уменьшая галлюцинации без изменения архитектуры LLM.

Основные работы в этой области:
- KAPING (Baek et al., 2023) - сопоставление сущностей в вопросах для извлечения связанных триплетов из графов знаний
- Wu et al. (2023) - преобразование этих триплетов в текстуализированные утверждения для повышения производительности LLM
- Sen et al. (2023) - модуль поиска, обученный на модели KGQA, для решения проблемы неадекватности поиска на основе сходства для сложных вопросов
- StructGPT (Jiang et al., 2023) - расширение LLMs данными из графов знаний, таблиц и баз данных

Важно отметить, что хотя LLMs с расширенным поиском хорошо работают с популярными сущностями и отношениями, они сталкиваются с трудностями при работе с менее популярными темами, и увеличение размера модели не улучшает их производительность в таких случаях.

#### 3.1.2. Расширенные графами знаний рассуждения

Методы расширенного графами знаний поиска эффективно отвечают на фактические вопросы, но для вопросов, требующих рассуждения, необходимы более продвинутые подходы, такие как декомпозиция сложных задач на управляемые подзапросы (Qiao et al., 2022; Liu et al., 2023).

Для имитации процесса человеческого рассуждения были разработаны методы:
- Chain of Thought (CoT) (Wei et al., 2022a)
- Chain of Thought with Self-Consistency (CoT-SC) (Wang et al., 2022)
- Program-Aided Language Model (PAL) (Gao et al., 2023)
- Reason and Act (ReAct) (Yao et al., 2022)
- Reflexion (Shinn et al., 2023)

Различные методы расширения знаний с использованием графов знаний, вдохновленные CoT и ToT (Tree of Thoughts), улучшают рассуждения в задачах как для конкретных доменов, так и для общих областей:
- "Rethinking with Retrieval" (He et al., 2022) - использует декомпозированные шаги рассуждения
- IRCoT (Trivedi et al., 2022) - чередует генерацию цепочек мыслей и извлечение знаний из графов
- MindMap (Wen et al., 2023) - подход "plug-and-play" для вызова рассуждений "graph-of-thoughts" в LLMs
- Reasoning on Graphs (RoG) (Luo et al., 2023) - использует графы знаний для создания достоверных путей рассуждения

Статья отмечает, что фундаментальный вопрос о том, действительно ли нейронные сети занимаются "рассуждениями", остается без ответа, и неясно, всегда ли следование правильному пути рассуждения приводит к точным ответам.

#### 3.1.3. Контролируемая знаниями генерация

Эти методы генерируют знания с использованием языковой модели, а затем используют зондирование или вызовы API для задач:
- Liu et al. (2021) использовали вторую модель для создания связанных с вопросами утверждений знаний для выводов
- Binder (Cheng et al., 2022) использует Codex для анализа контекста и создания вызовов API задач
- KB-Binder (Li et al., 2023) также использует Codex для создания логических черновиков для вопросов
- Brate et al. (2022) создают промпты в стиле заполнения пропусков для сущностей в графах знаний
- KnowPrompt (Chen et al., 2022) генерирует промпты из предобученной модели и настраивает их для извлечения отношений
- BeamQA (Atif et al., 2023) использует языковую модель для создания путей вывода

Ограждения в генеративном ИИ устанавливают операционные границы для моделей, обеспечивая безопасную и надежную генерацию выходных данных. NeMo guardrails (Rebedea et al., 2023) от Nvidia направляют потоки разговоров в корпоративных приложениях для соответствия стандартам безопасности.

### 3.2. Обучение с учетом знаний

Авторы рассматривают второй этап, где можно решить проблемы галлюцинаций в LLMs: использование графов знаний для оптимизации процесса обучения путем улучшения качества обучающих данных на этапе предварительного обучения модели или путем тонкой настройки предварительно обученной языковой модели (PLM).

#### 3.2.1. Предварительное обучение с учетом знаний

Качество и разнообразие обучающих данных имеют решающее значение для уменьшения галлюцинаций в LLMs. Интеграция графов знаний улучшает способности понимания LLMs и помогает в создании текста, который точнее отражает сложности реальных сущностей. 

Авторы выделяют следующие категории подходов:

1. **Модели с расширенными знаниями**:
   - ERNIE (Zhang et al., 2019) - использует маскированное языковое моделирование (MLM) и предсказание следующего предложения (NSP)
   - ERNIE 3.0 (Sun et al., 2021a) - интегрирует авторегрессивную модель с сетью автокодирования
   - Rosset et al. (2020) - представили вход с учетом знаний через словарь токенизатора сущностей

2. **Маскирование с учетом знаний**:
   - Схемы маскирования сущностей на основе графов знаний (Shen et al., 2020; Zhang et al.)
   - Sentiment Knowledge Enhanced Pre-training (SKEP) (Tian et al., 2020) - использовал маскирование сентимента

3. **Слияние знаний**:
   - Методы интегрируют графы знаний в LLMs с использованием кодировщиков графовых запросов (Wang et al., 2021; Ke et al., 2021; He et al., 2019)
   - JointLK (Sun et al., 2021b) - использовал слияние знаний и совместные рассуждения
   - LKPNR (Runfeng et al., 2023) - объединил LLMs с графами знаний для создания персонализированной системы рекомендации новостей

4. **Зондирование знаний**:
   - Включает исследование языковых моделей для оценки их фактических и общих знаний (Petroni et al., 2019)
   - Rewire-then-Probe (Meng et al., 2021) - представил самоконтролируемый контрастивный подход к зондированию
![Предварительная подготовка с учетом знаний от Knowledge Fusion](https://arxiv.org/html/2311.07914v2/extracted/5474405/Figures/Method_2.png)
#### 3.2.2. Тонкая настройка с учетом знаний

Тонкая настройка адаптирует LLMs к конкретным доменам путем обучения их на соответствующих наборах данных, используя выбранные архитектуры и гиперпараметры для модификации весов модели с целью улучшения производительности задачи. Графы знаний могут дополнительно настраивать эти модели для обновления и расширения их внутренних знаний для задач специфичных для домена.

Основные работы:
- SKILL (Moiseev et al., 2022) - использовал синтетические предложения, преобразованные из WikiData
- KELM (Agarwal et al., 2020) - использовал графы знаний для тонкой настройки контрольных точек предварительно обученной модели
- KGLM (Youn and Tagkopoulos, 2022) - использовал слой внедрения сущностей-отношений с триплетами графа знаний

Эффективность тонкой настройки языковых моделей для обновления знаний требует дальнейшего исследования. Onoe et al. (2023) показали, что хотя модели могут вспоминать факты о новых сущностях, делать выводы на их основе сложнее.

### 3.3. Проверка с учетом знаний

Третья категория методов использует структурированные данные в качестве механизма проверки фактов и предоставляет ссылку для модели для проверки информации. Графы знаний могут обеспечивать всеобъемлющие объяснения и могут использоваться для обоснования решений моделей.

Основные методы:
- Модель языка с учетом фактов, KGLM (Logan IV et al., 2019) - обращалась к графу знаний для создания сущностей и фактов, релевантных контексту
- SURGE (Kang et al., 2022b) - извлекает триплеты с высоким сходством, релевантные контексту, как подграф из графа знаний
- Классификатор "Text critic" (Lango and Dušek, 2023) - предложен для руководства генерацией
- FOLK (Wang and Shu, 2023) - использовал предикаты логики первого порядка (FOL) для проверки утверждений в дезинформации онлайн

Эти методы также помогают обеспечивать согласованность между фактами, устраняя необходимость в трудоемких данных с аннотациями человека и повышая надежность создаваемого контента.

![Сравнительные характеристики методов LLM, улучшенных с помощью Knowledge Graph](https://github.com/rocoss/Awesome-RAG/blob/main/images/ontology/2.png)

## 4. Обсуждение, проблемы и будущее

В этом разделе авторы оценивают эффективность методов повышения качества LLMs с помощью графов знаний для уменьшения галлюцинаций и повышения производительности и надежности. Также они определяют ключевые проблемы, связанные с каждым методом, и предлагают потенциальные направления исследований в этой развивающейся области.

### 4.1. Ресурсы

Таблица 1 детализирует ключевые характеристики различных методов расширения LLMs с помощью графов знаний, подчеркивая их применение в конкретных отраслях с использованием графов знаний для конкретных доменов. 

Примеры применения:
- Mindmap (Wen et al., 2023) - продемонстрировал применение в здравоохранении, расширяя клинические наборы данных с GPT-4
- Meng et al. (2021) - предварительно обучили модели T5 и BART с использованием биомедицинского графа знаний
- LKPNR (Runfeng et al., 2023) - предварительно обучил энкодеры LM и графов на журналах кликов пользователей MIND-200K для предоставления персонализированных рекомендаций новостей
- Martino et al. (2023) - использовали внедрение знаний для уменьшения галлюцинаций при ответе на отзывы клиентов
- Baldazzi (2023) - провел тонкую настройку T5-large на корпоративном графе знаний для финансового обслуживания клиентов

### 4.2. Метрики оценки

Для оценки эффективности расширения графа знаний в уменьшении галлюцинаций в LLMs применялись различные критерии:

- **Accuracy**: Сравнение точности с расширенными знаниями из графов знаний и без них (Baek et al., 2023; Zhang et al., 2023b)
- **Top-K и MRR**: Производительность поиска измерялась по релевантности извлеченных триплетов для генерации ответов. Mean Reciprocal Rank (MRR) и Top-K точность определяли ранг правильно извлеченных триплетов, содержащих ответ (Baek et al., 2023; Sen et al., 2023)
- **Hits@1**: Оценивает точность ответа и исследует охват ответов на вопросы с множественным выбором (Luo et al., 2023; Wu et al., 2023; Wei et al., 2023)
- **Execution Accuracy (EA)**: Метод контролируемой генерации, такой как Binder (Cheng et al., 2022), использует EA как метрику для измерения точности в семантическом анализе, генерации вызова API и успешности выполнения кода
- **Exact Match (EM)**: Производительность модели после тонкой настройки оценивалась с использованием оценок EM на тестовых наборах (Moiseev et al., 2022)
- **Human Evaluation**: Методы валидации оценивались вручную для оценки качества объяснения, охвата, логической обоснованности, беглости и фактической точности завершения предложений (Wang and Shu, 2023; Kang et al., 2022b)

### 4.3. Анализ производительности

Авторы выделяют несколько ключевых наблюдений относительно производительности методов:

- **Извлеченные факты улучшают малые LLMs**: Меньшие модели из-за ограниченного пространства параметров испытывают трудности с включением обширных знаний в предварительное обучение. Расширение фактами из графов знаний, а не увеличение размера модели, повышало правильность ответов более чем на 80% для задач вопрос-ответ (Baek et al., 2023; Sen et al., 2023; Wu et al., 2023)

- **Пошаговое рассуждение более эффективно в крупных моделях**: Вариации методов CoT предлагают экономичный контроль и настройку для конкретных задач, повышая производительность модели. Например, RoG (Luo et al., 2023) сообщил об увеличении точности ChatGPT с 66.8% до 85.7% в задачах рассуждения с расширением графа знаний

- **Контролируемая генерация повышает производительность**: Методы генерации, контролируемые знаниями, превосходят базовые модели в точности и контекстуальной релевантности, улучшая их способность обрабатывать разнообразные запросы (Chen et al., 2022; Cheng et al., 2022; Atif et al., 2023)

- **Предварительное обучение и тонкая настройка затратны**: Они значительно повышают производительность задач в конкретных доменах, но требуют существенных вычислительных ресурсов

- **Проверка фактов обеспечивает надежность**: Проверка знаний через проверку фактов уменьшает галлюцинации, проверяя данные, созданные моделью, с графом знаний, но увеличивает вычислительную нагрузку и может пропустить некоторые неточности (Kang et al., 2022b; Lango and Dušek, 2023)

### 4.4. Анализ тенденций

Рисунок 5 показывает тенденции исследований с использованием различных методов расширения графа знаний с 2019 по 2023 годы. Размер пузыря представляет количество статей для каждой категории расширения графа знаний, от одной до восьми.
![Рисунок 5](https://arxiv.org/html/2311.07914v2/x1.png)
Основные наблюдения:
- Методы предварительного обучения путем добавления графов знаний в обучающий корпус преобладали в ранние годы разработки языковой модели
- После обширной серии GPT LLMs, переобучение огромной модели с миллиардами параметров стало непрактичным и ресурсоемким
- Больше усилий было направлено на тонкую настройку моделей с данными для конкретных задач без обучения с нуля
- Совсем недавно произошел сдвиг в сторону использования методов расширенного знаниями поиска, рассуждения, генерации и валидации без дополнительных затрат на обучение

### 4.5. Будущие направления

Авторы предлагают несколько потенциальных направлений исследований для дальнейшего изучения:

1. **Улучшение качества графов знаний**:
   - **Контекстно-зависимые**: Динамические графы знаний, которые постоянно адаптируются к меняющимся контекстам и новой информации
   - **Решение проблем предвзятости**: Алгоритмы, учитывающие справедливость, в графах знаний
   - **Знания из разных доменов**: Интеграция знаний из различных областей в единый граф
   - **Мультимодальность**: Добавление мультимодальных данных, таких как изображения, видео и аудио, в графы знаний

2. **LLMs на основе смеси экспертов (MoE)**: Оптимизация архитектуры MoE для масштабирования LLMs и увеличения их емкости без увеличения вычислений

3. **Объединение символьного и подсимволического**: Ткани знаний, такие как символьные графы знаний и подсимволические векторы, обеспечивают разнообразные рассуждения в LLMs

4. **Синергия LLM и графов знаний**: LLMs используются для предсказания связей и пополнения графа знаний. Синергия LLM и графов знаний - потенциальное направление, где оба компонента могут взаимно улучшать возможности друг друга

5. **Понимание причинно-следственных связей**: Включение причинности в графы знаний улучшит способность LLMs понимать причинно-следственные связи, значительно улучшая их возможности рассуждения и прогнозирования

## 5. Заключение

В этом обзоре авторы систематически исследуют интеграцию графов знаний в LLMs для смягчения галлюцинаций и повышения точности рассуждений. Они подчеркивают преимущества использования графов знаний для улучшения производительности LLM на различных этапах: при выводе, обучении модели и проверке выходных данных.

Несмотря на значительный прогресс, авторы подчеркивают необходимость постоянных инноваций и предлагают будущие направления для содействия развитию более продвинутых LLMs с расширенным графом знаний.

## 6. Ограничения

В этом разделе авторы признают ограничения своего исследования:

- **Ссылки и методы**: Из-за ограничений по объему статьи могут быть не включены все соответствующие ссылки и подробная техническая информация. Исследование в основном сосредоточено на современных методах, разработанных между 2019 и 2023 годами, полученных в основном из авторитетных конференций и платформ, таких как ACL, EMNLP, NAACL, ICLR, ICML и arXiv.

- **Таксономия и сравнение**: Методы в основном были классифицированы на основе их основного подхода к расширению. В некоторых случаях гибридные исследования, включающие несколько подходов, могут быть классифицированы по-разному в зависимости от конкретных критериев. Анализ основан на производительности существующих работ с использованием текущих экспериментов и наборов данных. Учитывая быстрое развитие в этой области, ориентиры и базовые модели могут меняться, потенциально приводя к вариациям в этих оценках.

Авторы подтверждают, что материал основан на работе, поддержанной Национальным научным фондом в рамках гранта № 2114789.
