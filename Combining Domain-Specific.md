В данном обзоре представлен детальный анализ статьи «Combining Domain-Specific Models and LLMs for Automated Disease Phenotyping from Survey Data» (Комбинирование доменно-специфичных моделей и больших языковых моделей для автоматизированного фенотипирования заболеваний на основе данных опросов), опубликованной авторами Gal Beeri, Benoit Chamot, Elena Latchem и др. Статья посвящена исследованию возможностей комбинирования доменно-специфичной модели BERN2 с большими языковыми моделями (LLMs) для автоматизации извлечения и нормализации информации о заболеваниях из данных опросов. Обзор структурирован по ключевым аспектам работы, включая введение, методологию, результаты, обсуждение и выводы, с акцентом на технические и математические детали.

## Введение и контекст исследования

Статья начинается с описания проблемы отсутствия стандартизированных онтологий для описания характеристик здоровья и исходов в биомедицинских исследованиях, что затрудняет интероперабельность и гармонизацию данных между различными исследованиями1. Ручная классификация данных опросов в фенотипические и онтологические категории заболеваний является трудоемкой, подверженной ошибкам и дорогостоящей задачей. Авторы предлагают использовать методы обработки естественного языка (NLP), включая распознавание именованных сущностей (NER) и их нормализацию (NEN), для автоматизации этого процесса1.

Целью исследования является разработка подхода, который автоматически и точно идентифицирует и категоризирует информацию о заболеваниях в данных опросов, собранных в рамках проекта ORIGINS - когортного исследования 10 000 семей в Западной Австралии, направленного на изучение ранних факторов развития неинфекционных заболеваний1. Для нормализации данных используется онтология MeSH (Medical Subject Headings), разработанная Национальной библиотекой медицины США, которая обеспечивает иерархическую структуру медицинских терминов1.

Ключевой инновацией является комбинирование доменно-специфичной модели BERN2, оптимизированной для задач NER и NEN в биомедицинских текстах, с LLMs для повышения точности и эффективности фенотипирования1. Авторы подчеркивают, что общие LLMs, такие как ChatGPT, показывают ограниченную эффективность в биомедицинских задачах NLP, что подтверждается предыдущими исследованиями, и делают акцент на необходимости интеграции специализированных моделей1.

## Методология

## Источник данных и их обработка

Исследование базируется на данных когорты ORIGINS, включающей более 57 785 записей опросов, собранных через платформу REDCap. Эти данные охватывают демографию, образ жизни, окружающую среду и здоровье1. Для анализа был извлечен подмножество данных, включающее уникальные вопросы и ответы, в том числе свободные текстовые ответы, которые отличаются высокой вариативностью. Данные были деидентифицированы и централизованы в облачном хранилище AWS S3. Предобработка включала стемминг, расширение аббревиатур, приведение текста к нижнему регистру, исправление орфографических и пунктуационных ошибок1.

## Автоматизированный конвейер фенотипирования с BERN2

Для автоматизированного фенотипирования была выбрана модель BERN2, которая демонстрирует высокую точность в задачах NER и NEN для биомедицинских текстов1. BERN2 использует BioBERT для распознавания упоминаний заболеваний и нейронные методы нормализации, такие как BioSyn, который показал лучшие результаты в предварительных экспериментах по сравнению с другими подходами (sieve и hybrid)1. Модель была адаптирована для обработки больших объемов данных опросов: код был оптимизирован для пакетной обработки, интегрирован в облачную среду AWS SageMaker, а формат ввода-вывода изменен для соответствия структуре данных REDCap1. Нормализация проводилась к онтологии MeSH, которая, несмотря на меньшую детализацию по сравнению с другими базами, обеспечивает высокую структурированность и снижает неоднозначность1.

## Ручная аннотация для создания эталонного набора данных

Для оценки точности автоматизированного конвейера был создан эталонный набор данных (ground truth) путем ручной аннотации 100 записей опросов. Аннотация проводилась двумя независимыми исследователями с использованием программного обеспечения Doccano, а расхождения разрешались третьим старшим исследователем1. Выборка была сбалансирована, включая записи с ожидаемыми и неожиданными упоминаниями заболеваний, а также различные типы вопросов (свободный текст, бинарные, выпадающие списки и др.), что обеспечило репрезентативность оценки1.

## Интеграция больших языковых моделей (LLMs)

Авторы исследовали потенциал LLMs для повышения точности фенотипирования, используя модели Mistral 7B, Mixtral 8x 7B, Llama 2 7B, Llama 3 8B и Llama 3 70B1. LLMs применялись в двух основных сценариях:

- **Оценка вывода BERN2**: Использование контекстной осведомленности LLMs для проверки нормализации заболеваний, выполненной BERN2, с учетом контекста вопросов и ответов1.
    
- **Цепочка LLMs для валидации**: Последовательное использование нескольких LLMs, где одна модель генерирует вывод (например, предполагаемый концепт заболевания), а другая оценивает его корректность1.
    

## Техники оптимизации взаимодействия с LLMs

Для улучшения производительности LLMs были протестированы различные подходы:

- **Few-Shot Inference (FSI)**: Использование 5-шагового вывода с примерами для повышения точности1.
    
- **Chain-of-Thought (CoT) Prompting**: Применение подсказок, побуждающих модель генерировать промежуточные шаги рассуждений (например, «давайте подумаем шаг за шагом»)1.
    
- **Retrieval-Augmented Generation (RAG)**: Комбинация с CoT для доступа к онтологии MeSH во время генерации текста, что снижает галлюцинации и повышает точность1.
    
- **Instructional Fine-Tuning (IFT)**: Тонкая настройка моделей Mixtral 8x 7B и Llama 3 8B на данных ORIGINS для адаптации к задаче нормализации1.
    
- **Retrieval Augmented/Aware Fine-Tuning (RAFT)**: Включение доменных знаний в LLMs с использованием тренировочных данных, содержащих вопросы, отвлекающие документы, правильные документы и ответы с рассуждениями1.
    
- **FSI с RAG и бинарными флагами**: Использование флагов для управления доступом к внешним данным и примерам1.
    

## Метрики оценки

Производительность моделей оценивалась с использованием эталонного набора данных и следующих метрик:

- **Согласование упоминаний**: Точное совпадение начальных и конечных индексов упоминаний заболеваний (даже частичные пересечения считались несоответствиями)1.
    
- **Согласование концептов**: Точное совпадение ID концепта между выводом модели и эталонным набором1.
    
- **Метрики матрицы ошибок**:
    
    - True Positive Rate (Recall): TP/(TP+FN)\text{TP} / (\text{TP} + \text{FN})TP/(TP+FN)1
        
    - False Positive Rate: FP/(TN+FP)\text{FP} / (\text{TN} + \text{FP})FP/(TN+FP)1
        
    - Precision: TP/(TP+FP)\text{TP} / (\text{TP} + \text{FP})TP/(TP+FP)1
        
    - F1 Score: 2×(Precision×Recall)/(Precision+Recall)2 \times (\text{Precision} \times \text{Recall}) / (\text{Precision} + \text{Recall})2×(Precision×Recall)/(Precision+Recall)1
        
    - Accuracy: (TP+TN)/(TP+TN+FP+FN)(\text{TP} + \text{TN}) / (\text{TP} + \text{TN} + \text{FP} + \text{FN})(TP+TN)/(TP+TN+FP+FN)1
        
- **ROUGE-n**: Оценка пересечения n-грамм между сгенерированными и эталонными текстами1.
    
- **Average Cosine Similarity**: Измерение когерентности текста через косинусное сходство между векторами предложений1.
    

## Результаты

## Производительность BERN2

Модель BERN2 показала высокую точность в задачах распознавания упоминаний заболеваний (NER) и их нормализации (NEN). F1-оценка составила 87.9% для NER и 83.1% для NEN, а точность (accuracy) достигла 83.1% и 79.2% соответственно1. Высокая доля истинно положительных результатов (93.2% для NER) и низкая доля ложноположительных (35.7%) подтверждают эффективность модели в идентификации заболеваний при минимальном количестве ошибок1.

## Оценка LLMs

## Zero-Shot Prompting

Результаты zero-shot prompting варьировались в зависимости от модели и типа подсказки. Mixtral 8x 7B достигла наивысшей точности (83.3%) с подсказкой «Concept vs. Concept», но показала высокий уровень галлюцинаций (16.7%)1. Mistral 7B продемонстрировала умеренную точность (71.2%) с той же подсказкой, но с более высоким уровнем галлюцинаций (28.8%)1. Подсказка «Concept vs. Mention» снизила точность для обеих моделей (76.5% и 58.5% соответственно)1.

## Fine-Tuned Models

Тонкая настройка LLMs на данных ORIGINS привела к незначительным улучшениям. Mixtral 8x 7B с 4 классами достигла F1-оценки 80% для согласования с BERN2 и 88.9% для согласования с эталонным набором, что значительно выше базовой модели (19.3% и 20.97%)1. Однако увеличение числа классов до 10 ухудшило результаты, а Llama 3 8B показала крайне низкие F1-оценки (6.78% и 6.25%)1. Добавление RAG к тонкой настройке дало лишь маргинальные улучшения для Mixtral 8x 7B1.

## Few-Shot Inference с RAG

Комбинация FSI и RAG привела к значительным улучшениям. Llama 3 8B достигла F1-оценки 97% по ROUGE-1, с высокой точностью (97%) и полнотой (97%), а также когерентностью 90%1. Llama 3 70B и Mixtral 8x 7B также показали улучшения, хотя и меньшие (F1 88% и 76% соответственно)1. Это подчеркивает преимущества предоставления LLMs структурированных примеров и доступа к внешним знаниям1.

## Chain-of-Thought Prompting

CoT prompting не улучшил производительность LLMs. Llama 3 8B показала наилучшие результаты без CoT (нормализованная производительность 1.00, истинно положительные 82.6%), тогда как добавление CoT (простого, сильного или гибридного) снизило показатели1. Для Llama 3 70B лучшие результаты были с сильным CoT (нормализованная производительность 0.91), но они все равно уступали Llama 3 8B без CoT1. Авторы связывают это с малым размером моделей (<100B параметров) и возможной путаницей в процессе рассуждений1.

## Embeddings

Использование эмбеддингов оказало смешанное влияние. Стандартный эмбеддинг показал лучшие результаты по ROUGE-1 (F1 66%, точность 72%, полнота 64%) и когерентности (84%)1. Эмбеддинг PubMed дал наихудшие результаты, а Jina - умеренные, но с низкой когерентностью (75%)1.

## Обсуждение

## Анализ результатов

BERN2 подтвердила свою высокую эффективность для задач NER и NEN, что делает ее подходящей для извлечения и стандартизации данных о заболеваниях из сложных опросов1. Интеграция LLMs дала смешанные результаты: zero-shot prompting показал потенциал, но требует тщательного выбора модели и подсказки для минимизации галлюцинаций1. Тонкая настройка на данных ORIGINS не принесла значительных улучшений, что может быть связано с ограниченным объемом или разнообразием данных1. Наиболее перспективным оказался подход FSI с RAG, который существенно повысил точность и когерентность1. CoT prompting оказался неэффективным, вероятно, из-за ограничений размера моделей1.

## Ограничения исследования

Авторы отмечают несколько ограничений: малый размер ручного аннотированного набора данных, что могло повлиять на оценку некоторых техник, и ограниченные вычислительные ресурсы для тонкой настройки и тестирования больших LLMs1. Это подчеркивает необходимость дальнейших исследований с использованием более крупных наборов данных и мощных моделей1.

## Сравнение с предыдущими исследованиями

Результаты согласуются с предыдущими выводами о ограниченной эффективности общих LLMs в биомедицинских задачах NLP и необходимости доменно-специфичных моделей1. Комбинация BERN2 с LLMs, особенно с FSI и RAG, представляет собой новаторский подход, который может быть расширен в будущем1.

## Заключение

Исследование демонстрирует потенциал комбинации доменно-специфичных моделей, таких как BERN2, с LLMs для автоматизированного фенотипирования заболеваний из данных опросов. Наиболее эффективным оказался подход FSI с RAG, который значительно улучшил точность и когерентность результатов1. Несмотря на ограничения, связанные с объемом данных и вычислительными ресурсами, работа предлагает перспективное направление для ускорения биомедицинских исследований через эффективную гармонизацию данных. Будущие исследования должны сосредоточиться на расширении наборов данных, использовании более мощных LLMs и дальнейшей оптимизации стратегий интеграции1.